{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### import necessary libraries :\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car = pd.read_csv('car.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car.head()### understaidning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### as the number of attributes and features are less , we could factorize the string attribute from 0 to 1,2,3 etc\n",
    "car.safety=pd.factorize(car.safety)[0]### low = 0; 1 = mid ; 2=high\n",
    "car.luggage_boots= pd.factorize(car.luggage_boots)[0]#### small = 0;med = 1 , big=2\n",
    "car.label = pd.factorize(car.label)[0]### unacc = 0 , acc = 1 , vgood = 2 ,good = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### as our factorize will start from 0 so in that case 0 : vhigh , but as it a categorical value so we make an extra list and transform\n",
    "#### the data from highest to lowest order \n",
    "buying = {'vhigh':3,'high':2,'med':1,'low':0}\n",
    "car.buying =[buying[items]for items in car.buying]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maintainance = {'vhigh':3,'high':2,'med':1,'low':0}\n",
    "car.maintainance =[maintainance[items]for items in car.maintainance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doors = {'2':2,'3':3,'4':4,'5more':5}\n",
    "car.doors =[doors[items]for items in car.doors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = {'2':2,'4':4,'more':5}\n",
    "car.person =[person[items]for items in car.person]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####normalize the input parameters : \n",
    "from sklearn.preprocessing import Normalizer\n",
    "array = car.values\n",
    "X = array[:,0:6]####input features , first 6 columns\n",
    "scaler = Normalizer().fit(X)\n",
    "X_norm = scaler.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y =array[:,6]####output \n",
    "dum_Y=tf.keras.utils.to_categorical(Y)### we create a categorical dummy variable which detects \n",
    "###[1,0,0,0]= unacc , [0,1,0,0]=acc, etc\n",
    "print (dum_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###performing a train - test split where 40 % of our data is used to test the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X_norm,dum_Y,test_size = 0.40 ,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### building up the model : \n",
    "model = tf.keras.models.Sequential()#### we want to have a feed forward network\n",
    "model.add(tf.keras.layers.Flatten())### flattening the data helps to compress the input in such a which allows the network perform better\n",
    "### we would want to have 2 hidden layers with 128 neurons and each have rectified linear function as the activation function \n",
    "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "### as the labels are 0 to 9 so 10 output nodes are needed and the activation function is softmax function \n",
    "model.add(tf.keras.layers.Dense(10,activation = tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(4, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### evaluation : \n",
    "val_loss, val_acc = model.evaluate(X_train, Y_train)\n",
    "print(val_loss)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(Y_test,prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
